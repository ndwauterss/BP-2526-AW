%---------- Inleiding ---------------------------------------------------------

\paragraph{Opmerking}

Dit voorstel is gebaseerd op het onderzoeksvoorstel dat werd geschreven in het kader van het vak Research Methods dat ik vorig academiejaar heb uitgewerkt.

\section{Inleiding}%
\label{sec:inleiding}

Serverless computing maakt het mogelijk voor ontwikkelaars om toepassingen te bouwen zonder het beheer van infrastructuur. \textcolor{purple}{Azure Functions} is hierin een populair platform en \textcolor{purple}{wordt door Agromanager gebruikt voor functies met een dynamische workload binnen een App Service Plan. Deze service draait continu, maar wordt slechts voor korte perioden in het jaar gebruikt. Hierdoor ondervinden zij onnodige kosten en prestatieproblemen bij hoge belasting.}

Door de introductie van nieuwe alternatieven die mogelijks beter aansluiten bij deze toepassingen, stelt Agromanager zich de vraag:

\textcolor{purple}{\textbf{In welke mate kunnen serverless container-gebaseerde oplossingen bij verschillende cloudproviders de schaalbaarheid, prestaties en kostenefficiëntie verbeteren voor Azure Functions met dynamische en seizoensgebonden workload?}}

Om deze probleemstelling op te lossen, worden volgende deelvragen onderzocht:

\textcolor{purple}{
\begin{enumerate}
    \item Wat zijn de beperkingen van de huidige toepassing?
    \item Wat maakt de bestaande applicatie dynamisch en seizoensgebonden? 
    \item Welke architecturale en technische factoren zijn belangrijk bij de huidige toepassing? 
    \item Aan welke eisen moet een nieuwe oplossing voldoen om als succesvol aanzien te worden?
    \item Wat zijn de belangrijkste technische verschillen tussen de mogelijke oplossingen?
    \item Wat zijn de architecturale overwegingen en uitdagingen bij een migratie naar een andere oplossing?
    \item Welke impact heeft een migratie naar de mogelijke oplossingen? 
    \item Wat is de superieure oplossing?
\end{enumerate} 
}

De doelstelling van dit onderzoek is om via theoretische analyse en praktisch testen een onderbouwd advies te geven aan Agromanager. Concreet zal er een Proof-of-Concept ontwikkeld worden, waarbij er een vergelijkende analyse uitgevoerd zal worden op de resultaten. Dit zal aantonen wat de impact is van een migratie naar alternatief A of B in termen van kosten, schaalbaarheid en prestaties.

%---------- Stand van zaken ---------------------------------------------------

\section{Literatuurstudie}%
\label{sec:literatuurstudie}

\subsection*{Azure Functions}

Serverless computing ontkoppelt de ontwikkeling van een applicatie van het beheer van de onderliggende infrastructuur. Dit versnelt volgens \textcite{Ghorbian2025} het ontwikkelproces. 

Function-as-a-Service (FaaS) is onderdeel van deze serverless architectuur en zorgt ervoor dat stukjes logica uitgevoerd kunnen worden als een reactie op gebeurtenissen \autocite{Yussupov2021}. In dit onderzoek bevindt het probleemdomein zich in Azure Functions, het FaaS-platform van Microsoft. Hierbij kan er gekozen worden tussen verschillende hostingopties.

\subsection*{Dedicated Plan}

De bestaande toepassing bevindt zich in het Dedicated Plan. Hierbij draaien meerdere functies op dezelfde virtuele machines en kunnen\newline grootte en aantal instanties zelf bepaald worden\footnote{\label{fn:dedicated-plan}\url{https://learn.microsoft.com/en-us/azure/azure-functions/dedicated-plan}}. Net als bij traditionele web apps delen Function apps binnen dit Plan dezelfde resources\footref{fn:dedicated-plan}.  

\subsubsection*{Schaalbaarheid}
\label{sec:scaling-dedicated}

Het is mogelijk om manueel te schalen naar een ander App Service Plan bij deze hosting\footref{fn:dedicated-plan}. Dit geeft echter risico op inefficiënte toewijzing van resources met hogere kosten of prestatieproblemen als gevolg \autocite{VishalHazarika2024}. In de thesis van \textcite{Falck2024} wordt beweerd dat automatisch schalen in het Dedicated Plan kan zorgen voor langere opstarttijden. Er wordt ook aangeraden om autoscale-regels in te stellen op basis van wiskundige formules om een ideaal omschakelpunt te vinden \autocite{Falck2024}.

\subsubsection*{Prestaties}

Microsoft\footref{fn:dedicated-plan} geeft het advies om de instelling ``Always On'' aan te zetten. Dit voorkomt dat de applicatie inactief wordt wat voor een langere uitvoeringstijd zou zorgen\footref{fn:dedicated-plan}. Dit hostingplan maakt gebruik van een vaste toekenning van resources en is op deze manier een ideale oplossing voor toepassingen met een consistente workload\footnote{\label{fn:overview-hosing-plans}\url{https://learn.microsoft.com/en-us/azure/app-service/overview-hosting-plans}}. Anderzijds kan het volgens \textcite{VishalHazarika2024} net voor prestatieproblemen zorgen wanneer de workload dynamisch is en de toegewezen resources niet voldoende zijn. Deze problematiek ondervindt ook Agromanager. 

\subsubsection*{Kostenefficiëntie}

De kosten voor Azure Functions binnen het Dedicated Plan zijn afhankelijk van welk App Service Plan gekozen wordt, waarbij elke optie een bepaalde hoeveelheid geheugen, opslag en prijs per instantie bevat\footnote{\label{fn:pricing-windows-app-service}\url{https://azure.microsoft.com/nl-nl/pricing/details/app-service/windows}}. Door de vaste kost lijkt het minder interessant te zijn voor een functie met lange inactiviteit.

\subsection*{Azure Container Apps}

Azure Container Apps (ACA) maakt een combinatie mogelijk tussen serverless functies die draaien op containergebaseerde toepassingen\footnote{\url{https://learn.microsoft.com/en-us/azure/azure-functions/functions-container-apps-hosting}}. In tegenstelling tot andere hostingplannen vereist deze manier het gebruik van containers en een aangepaste CI/CD-aanpak, waarbij containerimages centraal staan \autocite{George2022}.

\subsubsection*{Schaalbaarheid}

Toepassingen op ACA kunnen schalen op basis van Kubernetes Event-driven Autoscaling (KEDA)\footnote{\label{fn:container-apps-overview}\url{https://learn.microsoft.com/en-us/azure/container-apps/overview}}. Dit is een lichtgewicht tool die schalen ondersteunt bij verschillende gebeurtenissen en regels\footnote{\url{https://keda.sh/docs/2.17/concepts}}. Volgens Microsoft\footnote{\label{fn:scale-app}\url{https://learn.microsoft.com/en-us/azure/container-apps/scale-app}} kan elke containergebaseerde toepassing meerdere schaalregels bevatten, waarbij schalen gebeurt van zodra er één regel bereikt wordt. Er kan ook ingesteld worden hoeveel replica's er minimum en maximum inzetbaar zijn, waarbij minstens nul gelijkstaat aan scale-to-zero\footref{fn:scale-app}.

Schalen met KEDA lijkt in de praktijktesten van \textcite{NeiraCampos2024} 29\% sneller te zijn dan klassieke schaalmechanismen bij een hoge piekbelasting. Daarnaast toonden deze testen ook aan dat er een hogere foutenmarge en meer resource-verbruik was bij intensieve verwerkingen wat meer kosten kan opleveren \autocite{NeiraCampos2024}. Volgens \textcite{Yang2024} komt dit doordat CPU-tijd pas toegewezen wordt wanneer het dit vereist en kan dit leiden tot latentie. Wanneer de toepassing ingesteld staat voor scale-to-zero zorgt dit voor cold starts, aangezien de container(s) terug geïnitialiseerd moeten worden \autocite{Yang2024}. 

\subsubsection*{Prestaties}

Schalen met KEDA lijkt in de praktijktesten van \textcite{NeiraCampos2024} 29\% sneller te zijn dan klassieke schaalmechanismen bij een hoge piekbelasting. Daarnaast toonden deze testen ook aan dat er een hogere foutenmarge en meer resource-verbruik was bij intensieve verwerkingen wat meer kosten kan opleveren \autocite{NeiraCampos2024}. Volgens \textcite{Yang2024} komt dit doordat CPU-tijd pas toegewezen wordt wanneer het dit vereist en kan dit leiden tot latentie. Wanneer de toepassing ingesteld staat voor scale-to-zero zorgt dit voor cold starts, aangezien de container(s) terug geïnitialiseerd moeten worden \autocite{Yang2024}. 

\subsubsection*{Kostenefficiëntie}

In ACA kan er gekozen worden voor een Consumption Plan. Wanneer de applicatie geconfigureerd is voor scale-to-zero, worden enkel de actieve replica's in rekening gebracht\footnote{\label{fn:container-apps-details}\url{https://azure.microsoft.com/en-us/pricing/details/container-apps}}. Bij een instelling op minstens één replica, moet er ook betaald worden voor de inactieve tijd, maar tegen een lager tarief dan de actieve tijd\footref{fn:container-apps-details}. Volgens \textcite{Oudheusden2024} is dit kostenmodel ideaal voor dynamische event-driven toepassingen met afwisselende workloads en krijg je hierbij ook gratis requests, vCPU-seconden en GiB-seconden. Het Dedicated Plan binnen ACA zorgt net zoals bij Azure Functions voor voorspelde prestaties en wordt er betaald naargelang het gekozen workload-profiel \autocite{Oudheusden2024}.

\subsection*{Google Cloud Run}

Google Cloud Run (GCR) is een volledig beheerd applicatieplatform waarop je functies of containers kunt laten draaien\footnote{\label{fn:what-is-grc}\url{https://docs.cloud.google.com/run/docs/overview/what-is-cloud-run}}. Dit betekent dat Google alle infrastructuur regelt, waardoor de ontwikkelaar zich kan focussen op het produceren van code. In het artikel van \textcite{Mahmoudi2023} wordt vermeld dat GCR gebouwd is op Knative. Dit is een platform gebaseerd op Kubernetes en abstraheert de complexiteit die komt kijken bij het deployen, builden en beheren van serverless workloads\footnote{\label{fn:knative}\url{https://knative.dev/docs/}}.

\subsubsection*{Schaalbaarheid}

Dynamische workloads kunnen opgevangen worden in GCR door het automatisch schalen op basis van waargenomen belasting \autocite{Mahmoudi2023}. Volgens \textcite{Mahmoudi2023} wordt er door het performantie model een afweging gemaakt tussen aantal instanties en responstijd. Of met andere woorden: kosten versus prestaties. Het platform ondersteunt ook scale-to-zero en is zelfs de default wanneer de minimum instanties niet ingesteld worden\footnote{\label{fn:grc-autoscaling}\url{https://docs.cloud.google.com/run/docs/about-instance-autoscaling}}.

\subsubsection*{Prestaties}

In het artikel van \textcite{Abraham2023} wordt gewaarschuwd dat scale-to-zero een cold start kan veroorzaken en geven ze de raad om de minimum instanties op één te zetten wanneer de container meer dan tien seconden nodig heeft om op te starten. Dit kan anders voor problemen zorgen, aangezien GCR requests niet langer dan tien seconden kan laten wachten \autocite{Abraham2023}.

\subsubsection*{Kostenefficiëntie}

In GCR krijgt men per maand een gratis hoeveelheid vCPU-seconden, GiB-seconden, requests en netwerkverkeer\footnote{\label{fn:grc-pricing}\url{https://cloud.google.com/run/pricing}}. Dit is ideaal voor testomgevingen of kleine toepassingen. De documentatie\footref{fn:grc-pricing} geeft aan dat wanneer deze gratis resources op zijn, er keuze is tussen twee prijsmodellen: request-based en instance-based (figuur: \ref{fig:instance-pricing-gcr}). Wanneer scale-to-zero is ingesteld, moet men niet betalen in geval er geen instanties lopen \autocite{Abraham2023}.

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{../graphics/billingGCR}
    \caption{\label{fig:instance-pricing-gcr} Prijsconfiguratie instantietijd \footref{fn:grc-pricing}}
\end{figure*}

\subsection*{Onderlinge vergelijking}

\subsubsection*{Schaalbaarheid}

Automatisch schalen in het Dedicated Plan kan volgens \textcite{Falck2024} enkel via complexe autoscale-regels. Scale-to-zero wordt ook afgeraden, omdat dit een langere uitvoeringstijd veroorzaakt\footref{fn:dedicated-plan}. ACA ondersteunt scale-to-zero en schaalt geavanceerd door het gebruik van KEDA\textsuperscript{\hyperref[fn:container-apps-overview]{\ref*{fn:container-apps-overview}},\hyperref[fn:scale-app]{\ref*{fn:scale-app}}}. Volgens \textcite{Mahmoudi2023} schaalt GCR automatisch door het inschatten van waargenomen belasting. Scale-to-zero is hier ook mogelijk, maar heeft nood aan opvolging \autocite{Abraham2023}. In de context van een dynamische workload met lange inactiviteitsperioden lijkt ACA de beste oplossing op vlak van schalen door KEDA. Al kan dit niet met zekerheid gezegd worden, aangezien GCR ook een geavanceerd schaalmechanisme heeft.

\subsubsection*{Prestaties}

Het Dedicated Plan geeft voorspelde prestaties door de vast toegewezen resources\footref{fn:overview-hosing-plans}, maar ook kans op underprovisioning in een dynamische context \autocite{VishalHazarika2024}. ACA geeft mogelijke latentie bij een scale-to-zero instelling, maar kan goed reageren op piekbelasting \autocites{NeiraCampos2024}{Yang2024}. Scale-to-zero bij GCR kan ook een cold start veroorzaken en kan zelfs problemen geven wanneer opstart langer dan tien seconden duurt \autocite{Abraham2023}. Op vlak van prestaties lijkt het ook hier tussen ACA en GCR te gaan, omdat beiden dynamisch kunnen schalen bij piekbelasting. Hier rest enkel de vraag hoe lang een container nodig heeft om op te starten.

\subsubsection*{Kostenefficiëntie}

Kosten binnen het Dedicated Plan zijn vast door de vaste resources\footref{fn:pricing-windows-app-service}. ACA geeft de mogelijkheid tot een pay-per-use model of een vaste kost bij het Dedicated kostenmodel \autocite{Oudheusden2024}. GCR heeft ook twee kostenmodellen, maar beiden zijn pay-per-use\footref{fn:grc-pricing}. We kunnen vermoeden dat het Dedicated Plan minderwaardig is op vlak van kostenefficiëntie in deze context. Momenteel is het echter moeilijk om te zeggen of ACA minder kost dan GCR of vice versa.

%---------- Methodologie ------------------------------------------------------
\section{Methodologie}%
\label{sec:methodologie}

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{../graphics/GanttPlanningBP}
    \caption{\label{fig:gantt}Gantt diagram met de verschillende fasen en milestones van het onderzoek.}
\end{figure*}

De studie wordt op een iteratieve manier uitgevoerd, waarbij er op regelmatige basis feedback gevraagd en verwerkt wordt van de belanghebbenden. Tijdens het uitvoeren van dit onderzoek zal er ook tijd gaan naar het schrijven van een onderzoeksvoorstel en de bachelorproef. Bij de planning wordt uitgegaan van 8 uur werk per week zonder rekening te houden met eventuele vakanties, weekends en feestdagen.

\subsubsection*{Fase 1: Requirementsanalyse}

Het onderzoek start met een requirementsanalyse. Hierbij wordt een eerste analyse uitgevoerd op de toepassing in het probleemdomein. Hieruit volgt een eerste requirementslijst die via een interview met de belanghebbenden wordt aangevuld om de verwachtingen en richting van het onderzoek te bepalen. De uitkomst na deze fase is een lijst van eisen die kan dienen om de literatuurstudie op te starten. In deze fase worden de volgende deelvragen beantwoord: (1) Wat zijn de beperkingen van de huidige toepassing? (2) Wat maakt de bestaande applicatie dynamisch en seizoensgebonden? (3) Welke architecturale en technische factoren zijn belangrijk bij de huidige toepassing? (4) Aan welke eisen moet een nieuwe oplossing voldoen om als succesvol aanzien te worden? De verwachte tijdsduur bij deze fase is 32 uur verspreid over 4 weken.

\subsubsection*{Fase 2: Literatuurstudie}

In de volgende stap wordt er een uitgebreide literatuurstudie uitgevoerd die alle potentiële alternatieven opsomt en waarbij rekening gehouden wordt met de eerder verkregen requirementslijst. Hierbij wordt gekeken naar container-gebaseerde oplossingen van meerdere cloud providers. Voorbeelden zijn: Azure Container Apps, Google Cloud Run en AWS Fargate. Vervolgens wordt deze longlist besproken in een opvolgmeeting met Agromanager. Hieruit komt een shortlist van één à twee alternatieven die verder vergeleken zullen worden met de huidige manier van werken. Deze fase zal een antwoord geven op de deelvraag: (5) Wat zijn de belangrijkste technische verschillen tussen de mogelijke oplossingen? De tijdsinschatting voor deze fase is 80 uur verspreid over een periode van 20 weken. 

\subsubsection*{Fase 3: Proof-of-Concept}

Op dit moment kan de Proof-of-Concept (PoC) opgestart worden door het opzetten van de testomgevingen in de verschillende cloud omgevingen. Hierbij wordt een dynamische Function app gemigreerd naar de verschillende alternatieven. Bij deze migraties worden alle stappen en configuraties gedocumenteerd en zal er een antwoord komen op de deelvraag: (6) Wat zijn de architecturale overwegingen en uitdagingen bij een migratie naar een andere oplossing? Vervolgens worden relevante testscenario's uitgewerkt en uitgevoerd. De testen worden geautomatiseerd door middel van code in Python, waarbij variabelen gedefinieerd worden op één plaats. Er zal gekeken worden naar de prestaties en schaalbaarheid van elke toepassing. Dit houdt de volgende criteria in: cold start tijd, gemiddelde afhandelingstijd, throughput (aanvraag/seconde), CPU-gebruik, geheugengebruik en initialisatietijd van een nieuwe instantie.

Deze informatie wordt verkregen via Prometheus en Graphana en bijgehouden om een verdere analyse op uit te voeren. Elke benchmark wordt minstens 30 keer uitgevoerd per testomgeving, zodat er een normaal verdeling is van de gemiddelden (centrale limietstelling). Om de kosten te berekenen, zullen de prijzencalculators gebruikt worden van de verschillende cloud providers. Als resultaat zijn de nodige gegevens beschikbaar waarop het advies gebaseerd kan worden, alsook alle scripts die het automatiseren van de benchmarks mogelijk maken. De tijd die hiervoor nodig zal zijn, is 80 uur verspreid over 10 weken.

\subsubsection*{Fase 4: Verwerking resultaten}

Tot slot wordt er een analyse op de resultaten uitgevoerd. Dit gebeurt door het berekenen van de gemiddeldes, medianen, standaarddeviaties, minimale/maximale waarden en spreiding van resultaten. Deze nieuwe data wordt vervolgens gebruikt om statistische testen op uit te voeren. Hierbij zal gekeken worden naar een afhankelijke variabele (resultaten) en een onafhankelijke variabele (cloud provider). Deze bevindingen worden gevisualiseerd via Python en zal een antwoord bieden op de deelvragen: (7) Welke impact heeft een migratie naar de mogelijke oplossingen? (8) Wat is de superieure oplossing? Aan de hand van deze analyse en andere criteria zoals aanpassingen aan het deploymentproces en security, wordt er een advies opgesteld. Hierop kunnen de belanghebbenden zich baseren om een beslissing te nemen. Deze conclusie zal ongeveer 32 uur in beslag nemen verspreid over 4 weken.

%---------- Verwachte resultaten ----------------------------------------------
\section{Verwacht resultaat, conclusie}%
\label{sec:verwachte_resultaten}

Azure Container Apps en Google Cloud Run hebben een krachtige schaalbaarheid. Dit is één van de belangrijkste eigenschappen om uitdagingen rond dynamische toekenning van resources en het flexibel schalen op te vangen. De scale-to-zero zal hoogstwaarschijnlijk ook zorgen voor een lagere kost. Het helpt de inactiviteitsperiode overbruggen zonder kosten. Beiden hebben een andere manier van schalen en ook de kostenmodellen verschillen. Dit maakt het interessant om te vergelijken met elkaar. Ook andere technologieën kunnen nog niet uitgesloten worden, omdat de focus bij dit onderzoek op twee specifieke oplossingen lag. 

Dit onderzoek biedt inzicht in hoe serverless container-gebaseerde toepassingen omgaan met dynamische en seizoensgebonden functies en welke impact ze hierop kunnen hebben. Het doelpubliek kan dit gebruiken om een onderbouwde keuze te maken en zet de deur open om andere opties te onderzoeken. De testopzet is reproduceerbaar en herbruikbaar, waardoor het makkelijk aangepast kan worden naar een andere context. Zo draagt het bij aan data-gedreven beslissingen in een snel evoluerende serverless en containerized wereld.

